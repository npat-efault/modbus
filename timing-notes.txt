
MODBUS Over Serial Line, RTU timing issues
==========================================

The "MODBUS over Serial Line" spec [1], in section 2.5.1.1 describes
how, in RTU encoding, frames are delineated and detected using silent
intervals. While this may have been a reasonable choice in the 70s and
the 80s, it causes significant (and, frankly, unnecessary)
complications in modern computing environments.

Modern (and not so modern) UARTs have hardware FIFO queues on their
receivers. While these FIFOs can be disabled, and have the UART
operate in "one character at a time" mode, this is not always
practicable (you would have to write your own or modify the O/S UART
device driver) or desirable (it could causes high interrupt rates at
high baudrates, which may be overwhelming, especially if you are using
multiple ports at the same time).

Assume a 16-bytes FIFO (a typical size) configured to interrupt when
it's 100% full (the "worst case" for our discussion). Also assume a
bitrate of 9600bps (the lowest reasonable for a modbus bus, but not
uncommon). In this case, when the line is fully driven (characters
arrive back-to-back) we receive one interrupt every, approximately,
17ms. Even with the line at capacity, we will still detect "silent"
intervals of up to 17ms (or 16 char-times). Since modbus RTU encoding
uses silent intervals to detect frame boundaries, 17ms is the lowest
delay we have to use between frame transmissions in order to be able
to reliably determine frames at 9600bps---without modifying the serial
driver and reducing the FIFO fill level for triggering
interrupts. Actually, if we want to do the frame detection at
user-space, we may have to increase this delay even more to account
for O/S multitasking latency. The ModBus spec suggests delays of
approx 3.5ms for this baudrate. Totally untenable.

Using silent intervals to delineate frames is the most brain-dead
decision in an otherwise quite reasonable spec (as these things
go). An HDLC-like framing (had it been selected) would have cleared
all this mess.

All is not lost, however. We can still cope without resorting to
special-purpose drivers. Quite well for modbus masters, not so well
for slaves.

For masters: While we are supposed to detect frames based on silent
intervals, we do not *have* to. Since modbus is a request-response
protocol, if the master stops transmitting requests, the slaves will
stop transmitting responses, and in a short while the line will go
idle and remain so for as long as the master does not transmit
anything. So, for the master to sync with the bus, all it has to do is
stop transmitting requests and wait for the line to go idle for a
reasonable amount to time. After this, it knows that the first byte
received will be the first byte of a response frame. Responses are
formatted in such a way that by parsing the first few bytes we can
determine their length without relying on silent intervals. Assuming
of-course no errors on the line. If such an error occurs (we can
detect it using the frame's CRC, and which should not be often), the
master can re-sync by stopping transmitting and waiting for the line
to go idle for a reasonable amount of time. How much is reasonable?
More than the 16-20ms in the example above, or whatever can be
reliably determined. It should not matter much, as long as errors are
not frequent. In effect the master has to:

- Synchronize itself by stop transmitting and wait for the line to
  become idle for a reasonable amount of time.

- Parse response characters at the receiver (as they arrive) in order
  to determine the response frame's length.

- Make sure that there is a minimal delay between the reception of a
  response, and the transmission of the next request (which is easy to
  do). This is to avoid confusing slaves that use silent intervals to
  detect frame boundaries.

In the serial master implementation included in the modbus package the
"Delay" parameter is the amount of time to wait between the reception
of a response and the transmission of the next request. The
"SyncDelay" parameter is the amount of time the line should go idle
when the master is re-synchronizing, and "SyncWaitMax" is the maximum
amount of time the master should wait before abandoning the attempt to
re-synchronize. These parameters are only applicable for serial
clients that use RTU encoding.

For slaves: A similar approach can be followed for modbus-over-serial
slaves. The slave waits for the line to become idle for a reasonable
amount of time before it considers itself synchronized. Once this
happens then it parses request and response bytes at the receiver (as
they arrive) in order to determine frame lengths. This way it remains
synchronized as long as no error occurs on the line. If an error
occurs the slave will re-synchronize in the same manner (by waiting
for an idle line). Is such an idle condition guaranteed to ever occur
on the line, for a long enough time for the slave to synchronize?
Yes. When the master addresses our un-synchronized slave, the slave
will fail to reply and the master's response-timeout (if configured to
be long-enough) will guarantee an adequate idle time. If the master
never addresses our slave, then there is no reason for it to be
synchronized. Caveat: This approach does not work if the master
addresses our slave with broadcast requests, or if the master expects
the slave to be in no-reply mode. These are not very common. It also
requires reasonably long response timeouts to be configured on
masters. This is ok too.

There is still a problem, though: It is impossible for the slave to
determine the length of the frame by parsing the bytes as they
arrive. It is so because the slave has no way of knowing whether a
given frame is a response or a request and cannot decide what format
to expect. The only solution I can think of is this: For every frame
character received assume the frame is complete and check it's CRC. If
the CRC matches there is a good possibility we have detected the
correct boundaries. To be more sure, try also to unpack the frame (as
a request and a response) and determine if it is valid. If this check
passes too, then declare it a valid frame. It's costly, but CPU power
is not something lacking these days. It's a huge kludge, but it's the
best we can do. There is unfortunately the theoretical possibility
that even without any transmission errors we receive a bogus frame (if
a part of a true frame has a matching CRC and is also a valid frame).
